---
title: "p8105_hw5_yx2858"
author: "Yueyi Xu"
date: "2023-11-12"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
set.seed(1)
```

# Problem 1

### Describe the raw data

```{r}
raw_data = read_csv("homicide-data.csv")
```

There are `r nrow(raw_data)` rows and `r ncol(raw_data)` columns in the dataset of homicide.

```{r}
homicide = raw_data |>
  mutate(city_state = str_c(city, state, sep = ', '))
```

```{r}
homicide |>
  group_by(city) |>
  summarize(count = n()) |>
  knitr::kable(caption = "Total number of homicides")
```

```{r}
homicide |>
  group_by(city_state) |>
  summarize(total_homicides = n(),
            unsolved_homicides = sum(disposition == "Closed without arrest") +
                                       sum(disposition == "Open/No arrest")) |>
  arrange(desc(total_homicides)) |>
  knitr::kable(caption = "Total number of unsolved homicides")
```

From the table, Chicago has the highest number of homicides of 5535 and highest number of unsolved homicides of 4073. Tulsa, AL has the lowest number of homicides of 1 and lowest number of unsolved homicides of 0.


### Proportion test in Baltimore

```{r}
baltimore = homicide |>
  filter(city_state == "Baltimore, MD") |>
  mutate(unsolved_homicides = ifelse(disposition == "Open/No arrest" | disposition == "Closed without arrest", 1, 0))
```

```{r}
result_baltimore = 
  prop.test(sum(baltimore$unsolved_homicides), length(baltimore$unsolved_homicides)) |>
  broom::tidy()
result_baltimore

save(result_baltimore, file = "result/result_baltimore.RData")
```

The proportion test on Baltimore estimates that `r result_baltimore$estimate` of the homicides are unsolved, and 95% confidence interval for the proportion estimate is `r result_baltimore$conf.low` to `r result_baltimore$conf.high`.



# Problem 2

### Start with a dataframe containing all file names

```{r}
full_df = 
  tibble(
    files = list.files("data")
  ) |>
  mutate(files = str_c("data", files, sep = "/"))
```


### Iterate over file names and read in data for each subject

```{r}
tidy_df =
  full_df |>
  mutate(
    participant = map(files, read_csv),
    arm = case_when(str_detect(files, "exp") ~ "experiment",
                    str_detect(files, "con") ~ "control"),
    id = as.factor(parse_number(files))
  ) |>
  unnest(participant) |>
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "observations",
    names_prefix = "week_") |>
  mutate(week = as.numeric(week))
```




